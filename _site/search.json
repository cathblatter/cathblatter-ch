[
  {
    "objectID": "posts/2022/2022-01-27_random-stuff.html",
    "href": "posts/2022/2022-01-27_random-stuff.html",
    "title": "An (ever growing) list of random things in R",
    "section": "",
    "text": "This post should really just be a random list of things that R can do but I often forget about‚Ä¶."
  },
  {
    "objectID": "posts/2022/2022-01-27_random-stuff.html#print-calendar-in-r-console",
    "href": "posts/2022/2022-01-27_random-stuff.html#print-calendar-in-r-console",
    "title": "An (ever growing) list of random things in R",
    "section": "Print calendar in R console",
    "text": "Print calendar in R console\n\nsystem(\"cal\")\n\n   February 2023      \nSu Mo Tu We Th Fr Sa  \n          1  2  3  4  \n 5  6  7  8  9 10 11  \n12 13 14 15 16 17 18  \n19 20 21 22 23 24 25  \n26 27 28              \n                      \n\n\nBecause, why not? üòé It even goes for a whole year:\n\nsystem(\"cal 2021\")\n\n                            2021\n      January               February               March          \nSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  \n                1  2      1  2  3  4  5  6      1  2  3  4  5  6  \n 3  4  5  6  7  8  9   7  8  9 10 11 12 13   7  8  9 10 11 12 13  \n10 11 12 13 14 15 16  14 15 16 17 18 19 20  14 15 16 17 18 19 20  \n17 18 19 20 21 22 23  21 22 23 24 25 26 27  21 22 23 24 25 26 27  \n24 25 26 27 28 29 30  28                    28 29 30 31           \n31                                                                \n\n       April                  May                   June          \nSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  \n             1  2  3                     1         1  2  3  4  5  \n 4  5  6  7  8  9 10   2  3  4  5  6  7  8   6  7  8  9 10 11 12  \n11 12 13 14 15 16 17   9 10 11 12 13 14 15  13 14 15 16 17 18 19  \n18 19 20 21 22 23 24  16 17 18 19 20 21 22  20 21 22 23 24 25 26  \n25 26 27 28 29 30     23 24 25 26 27 28 29  27 28 29 30           \n                      30 31                                       \n\n        July                 August              September        \nSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  \n             1  2  3   1  2  3  4  5  6  7            1  2  3  4  \n 4  5  6  7  8  9 10   8  9 10 11 12 13 14   5  6  7  8  9 10 11  \n11 12 13 14 15 16 17  15 16 17 18 19 20 21  12 13 14 15 16 17 18  \n18 19 20 21 22 23 24  22 23 24 25 26 27 28  19 20 21 22 23 24 25  \n25 26 27 28 29 30 31  29 30 31              26 27 28 29 30        \n                                                                  \n\n      October               November              December        \nSu Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  Su Mo Tu We Th Fr Sa  \n                1  2      1  2  3  4  5  6            1  2  3  4  \n 3  4  5  6  7  8  9   7  8  9 10 11 12 13   5  6  7  8  9 10 11  \n10 11 12 13 14 15 16  14 15 16 17 18 19 20  12 13 14 15 16 17 18  \n17 18 19 20 21 22 23  21 22 23 24 25 26 27  19 20 21 22 23 24 25  \n24 25 26 27 28 29 30  28 29 30              26 27 28 29 30 31     \n31                                                                \n\n\nfurther reading and more elaborate stuff: https://www.garrickadenbuie.com/blog/r-console-calendar/"
  },
  {
    "objectID": "posts/2022/2022-02-24_renaming-variables.html",
    "href": "posts/2022/2022-02-24_renaming-variables.html",
    "title": "Different approaches to rename variables",
    "section": "",
    "text": "This was usually a rather small post with snippets but turned out to be much more interesting‚Ä¶\nLoading the necessary package\n\nlibrary(tidyverse)\n\nSample dataframe\nCreating a sample dataframe: the function tribble() lets you construct rowwise-tibbles (thus the R in tribble()). This is closer to the idea of data in a spreadsheet than the mirrored version with tibble() or data.frame().\n\ndf <- tibble::tribble(\n  ~id, ~pesnwi_leadership, ~pesnwi_sra, ~bernca_adl, ~bernca_docu,\n  1, 2.3, 2.1, 1.8, 1.4,\n  2, 2.0, 3, 2.1, 0.9,\n  3, 3.1, 3.5, 3.9, 3\n)\n\nThis is the equivalent code for the ‚Äòmirrored‚Äô version:\n\ndf <- \n  data.frame(\n                   id = c(1, 2, 3),\n    pesnwi_leadership = c(2.3, 2, 3.1),\n           pesnwi_sra = c(2.1, 3, 3.5),\n           bernca_adl = c(1.8, 2.1, 3.9),\n          bernca_docu = c(1.4, 0.9, 3)\n  )\n\nFinally, this is how the dataframe looks like:\n\ndf\n\n# A tibble: 3 √ó 5\n     id pesnwi_leadership pesnwi_sra bernca_adl bernca_docu\n  <dbl>             <dbl>      <dbl>      <dbl>       <dbl>\n1     1               2.3        2.1        1.8         1.4\n2     2               2          3          2.1         0.9\n3     3               3.1        3.5        3.9         3  \n\n\n\n\nManual renaming following the idea of newname = oldname. This is the approach you need to take for manual replacement of column-names (see an equivalent base-R code below). You can rename more than three variables like this, just add further combinations of newname = oldname‚Ä¶\n\ndf %>%\n  rename(\n    pesnwi_ls = pesnwi_leadership,\n    ration_adl = bernca_adl,\n    ration_docu = bernca_docu\n  )\n\n# A tibble: 3 √ó 5\n     id pesnwi_ls pesnwi_sra ration_adl ration_docu\n  <dbl>     <dbl>      <dbl>      <dbl>       <dbl>\n1     1       2.3        2.1        1.8         1.4\n2     2       2          3          2.1         0.9\n3     3       3.1        3.5        3.9         3  \n\n\n\n\n\nOf course its also possible to rename the columns with other approaches, e.g.¬†:\n\nnames(df)[names(df)==\"pesnwi_leadership\"] <- \"pesnwi_ls\""
  },
  {
    "objectID": "posts/2022/2022-02-24_renaming-variables.html#renaming-multiple-columns-at-once",
    "href": "posts/2022/2022-02-24_renaming-variables.html#renaming-multiple-columns-at-once",
    "title": "Different approaches to rename variables",
    "section": "Renaming multiple columns at once",
    "text": "Renaming multiple columns at once\n\nRenaming based on text-patterns with dplyr::rename_with()\nIt‚Äôs possible to rename multiple column-names based on matching text-patterns (regular expression). This is great if you need to rename multiple variables with the same pattern, but it only works if you can find such a pattern. If you‚Äôre in doubt which option to choose its probably safer to do the manual method above‚Ä¶\nFor the example dataframe, say we want to replace the prefix ‚Äúbernca‚Äù (the name of an instrument to measure rationed nursing care 1) by the more general term ‚Äúration‚Äù. This is possible with the following code:\n\ndf %>%\n  rename_with(\n    .fn = ~ stringr::str_replace(., pattern = \"bernca\", replacement = \"ration\"),\n    .cols = everything()\n  )\n\n# A tibble: 3 √ó 5\n     id pesnwi_leadership pesnwi_sra ration_adl ration_docu\n  <dbl>             <dbl>      <dbl>      <dbl>       <dbl>\n1     1               2.3        2.1        1.8         1.4\n2     2               2          3          2.1         0.9\n3     3               3.1        3.5        3.9         3  \n\n\nBy default, all columns get considered, but we could limit this or manually define the columns with c(bernca_adl, bernca_docu). Note that I used the {stringr} package for replacing the pattern ‚Äòbernca‚Äô with ‚Äòration‚Äô."
  },
  {
    "objectID": "posts/2022/2022-02-24_renaming-variables.html#renaming-based-on-names-defined-in-an-external-document-e.g.-xlsx",
    "href": "posts/2022/2022-02-24_renaming-variables.html#renaming-based-on-names-defined-in-an-external-document-e.g.-xlsx",
    "title": "Different approaches to rename variables",
    "section": "Renaming based on names defined in an external document (e.g.¬†xlsx)",
    "text": "Renaming based on names defined in an external document (e.g.¬†xlsx)\nImagine the following situation: a survey study with three timepoints was conducted over a timespan of 2 years: T0 as baseline, T1 = T0+12months and T2 = T0+24months.\nSome of the questions were only asked at baseline, some across all timepoints and selected variables only in T1 and T2. For several reasons (a.k.a. real-life data collection) this led to situations, where a variable named X12 in T0, did in fact not correspond to the variable named X12 in T1 and so on.\nIn total there were > 250 variables to rename and the person defining the new variables did not work with R. Thus, the solution was to store the information in an external spreadsheet and then write code to import this spreadsheet and rename based on it. But how?\nA spreadsheet was created in excel that essentially held information on the variable names of a specific questions across all time points. Additionally, the first column ‚Äòglobal‚Äô defines the new variable name that will be used across all datasets once the renaming took place. Below is a small example of how the excel-file looked like:\n\n\n\n\n\nglobal\nT0\nT1\nT2\n\n\n\n\nID\nID\nID\nID\n\n\nX1\nX1\nX3\nX2\n\n\nX2\nX4\nX10\nX11\n\n\nX3\n\nX2\nX12\n\n\n\n\n\n\n\n\nCreating sample datasets\nBelow I created some sample datasets to mimic T0, T1 and T2 and the information from the spreadsheet:\nFor the data from the surveys T0, T1, T2\n\norig_t0 <- tibble::tribble(\n  ~ID, ~X1, ~X4,\n  \"A\", \"m\", 1,\n  \"B\", \"x\", 2\n)\n\norig_t1 <-  tibble::tribble(\n  ~ID, ~X3, ~X10, ~X2,\n  \"AAA\", \"f\", 1, 44,\n  \"BBB\", \"x\", 2, 56,\n)\n\norig_t2 <-  tibble::tribble(\n  ~ID, ~X2, ~X11, ~X12,\n  \"FFF\", \"f\", 2, 53,\n  \"BGG\", \"f\", 1, 23,\n)\n\nInformation from the spreadsheet\n\nname_tbl <- tibble::tribble(\n  ~global, ~T0, ~T1, ~T2,\n  \"ID\", \"ID\", \"ID\", \"ID\",\n  \"X1\", \"X1\", \"X3\", \"X2\",\n  \"X2\", \"X4\", \"X10\", \"X11\",\n  \"X3\", NA_character_, \"X2\", \"X12\"\n)\n\n\n\nUsing a named vector to rename dataframes\ncheck also this tweet by @PipingHotData: https://twitter.com/PipingHotData/status/1497014703473704965?s=20&t=TA5bW8K-wxczoaW2Q6UWCQ\nAs noted above rename() takes its inputs following the usual tidyverse-style, meaning rename(newname = oldname). This can be translated to the situation at hand by using the corresponding columns from the spreadsheet to create a named vector that has the information newname as ‚Äòname‚Äô and oldname as value. tibble::deframe() is suitable for this situation as described in the help-page: > deframe() converts two-column data frames to a named vector or list, using the first column as name and the second column as value.\nFor T0\n\n# create a named vector\nhelper_rename_t0 <- name_tbl %>%\n  select(global, T0) %>% # take the two variables needed\n  drop_na() %>% # drop_na() is important here \n  deframe() # deframe creates the named vector\n\n# rename with !!! \n(global_t0 <- \n  orig_t0 %>%\n    rename(!!!helper_rename_t0))\n\n# A tibble: 2 √ó 3\n  ID    X1       X2\n  <chr> <chr> <dbl>\n1 A     m         1\n2 B     x         2\n\n\nFor T1\n\n# create a named vector\nhelper_rename_t1 <- name_tbl %>%\n  select(global, T1) %>% # take the two variables needed\n  drop_na() %>% # drop_na() is important here \n  deframe() # deframe creates the named vector\n\n# rename with !!! \n(global_t1 <- \n  orig_t1 %>%\n    rename(!!!helper_rename_t1))\n\n# A tibble: 2 √ó 4\n  ID    X1       X2    X3\n  <chr> <chr> <dbl> <dbl>\n1 AAA   f         1    44\n2 BBB   x         2    56\n\n\nFor T2\n\n# create a named vector\nhelper_rename_t2 <- name_tbl %>%\n  select(global, T2) %>% # take the two variables needed\n  drop_na() %>% # drop_na() is important here \n  deframe() # deframe creates the named vector\n\n# rename with !!! \n(global_t2 <- \n  orig_t2 %>%\n    rename(!!!helper_rename_t2))\n\n# A tibble: 2 √ó 4\n  ID    X1       X2    X3\n  <chr> <chr> <dbl> <dbl>\n1 FFF   f         2    53\n2 BGG   f         1    23\n\n\nFinally, using bind_rows() to combine all datasets\n\n(version1 <- bind_rows(global_t0, global_t1, global_t2))\n\n# A tibble: 6 √ó 4\n  ID    X1       X2    X3\n  <chr> <chr> <dbl> <dbl>\n1 A     m         1    NA\n2 B     x         2    NA\n3 AAA   f         1    44\n4 BBB   x         2    56\n5 FFF   f         2    53\n6 BGG   f         1    23\n\n\nThis approach worked very well, however some elements are repeated for every dataset (creating the helper vector, renaming), thus maybe a more functional programming approach might be suitable.\n\n\nUsing functional programming to rename all dataframes at once\nThe approach above works very well, yet sometimes its nice to have the output checked to the original content as well (see if the renaming was really correct).\nThe code presented here war written with help from the R4DS-online community, specifically Tyler Smith for the first option and @jonthegeek for the 2nd one.\nFirst option\n\n# create a long df with matching variable names\nvar_names <- \n  name_tbl %>% \n  rename(to = global) %>% \n  pivot_longer(-to, names_to = \"source\", values_to = \"from\") %>% \n  select(source, from, to) %>% \n  drop_na()\n\n\n# helper function to rename the cols\nrename_cols <- function(.data, from, to) {\n  dplyr::rename(.data, \n                !!!rlang::syms(\n                  purrr::discard(\n                    rlang::set_names(from, to), is.na(from))))\n}\n\n\n# helper function to table the cols\n# to compare their content\ntable_cols <- function(.data, cols, ...) {\n  purrr::map(cols, ~ base::table(.data[[.x]]), ...)\n}\n\n\n# creating a list of all dataframes that need to be renamed\ndata_list <- list(\n  T0 = orig_t0,\n  T1 = orig_t1,\n  T2 = orig_t2\n)\n\n# Create a nested tibble, define the variables to \n# be rename for each row, apply the renaming, finbally validate the\n# data_table (original dataframe) versus the output_table (renamed dataframe)\n\nmapped_object <- \n  enframe(data_list, name = \"source\", value = \"data\") %>%\n  mutate(mapping = map(source, ~ filter(var_names, source == .))) %>%\n  hoist(mapping, from = \"from\", to = \"to\") %>%\n  mutate(\n    output = pmap(list(data, from, to), rename_cols), # renaming\n    data_table = map2(data, from, table_cols, useNA = \"always\"), # validation\n    output_table = map2(output, to, table_cols, useNA = \"always\"), # validation\n    validate = map2_lgl(data_table, output_table, identical) # validation\n  )\n\n\n# from the mapped_pbject, \n# unnest the output - don't forget to store it into its own object\nmapped_object %>% \n  select(output) %>% \n  unnest(cols = output)\n\n# A tibble: 6 √ó 4\n  ID    X1       X2    X3\n  <chr> <chr> <dbl> <dbl>\n1 A     m         1    NA\n2 B     x         2    NA\n3 AAA   f         1    44\n4 BBB   x         2    56\n5 FFF   f         2    53\n6 BGG   f         1    23\n\n\nSecond option\nThe approach is very similar: use purrr::map2_dfr() to indicate the use of two lists (.x and .y) whereas .x is the list of the dataframes and .y is the list of the vectors with the names. The suffix _dfr() does bind_rows() to combine the results into one dataframe\n\n# rename \nmap2_dfr(\n  list(orig_t0, orig_t1, orig_t2),\n  list(name_tbl$T0, name_tbl$T1, name_tbl$T2), function(tdf, names) {\n    real_names <- name_tbl$global[!is.na(names)]\n    names <- keep(names, function(v) !is.na(v))\n    tdf %>%\n      rename(!!!rlang::syms(set_names(names, real_names)))\n  }\n)\n\n# A tibble: 6 √ó 4\n  ID    X1       X2    X3\n  <chr> <chr> <dbl> <dbl>\n1 A     m         1    NA\n2 B     x         2    NA\n3 AAA   f         1    44\n4 BBB   x         2    56\n5 FFF   f         2    53\n6 BGG   f         1    23\n\n\n\n\nTL;DR\n\nThere are many different options on to how to rename a variable\nThis post should give an overview of some of the possibilities I have worked with\nIMHO the best solution depends on the situation at hand - choose your pick!"
  },
  {
    "objectID": "posts/2021-03-06-installing-multiple-r-versions-aside/index.html",
    "href": "posts/2021-03-06-installing-multiple-r-versions-aside/index.html",
    "title": "Installing & using multiple R versions aside",
    "section": "",
    "text": "I started using the {renv}-package about a year ago and it has saved me multiple times already. What always baffled me though was the hint when opening an ‚Äòold‚Äô project where I used a previous version of R to set it up - how would I be able to ‚Äòswitch‚Äô back to an older version of R?\nI remembered Garrick Aiden-Buie mentioning Rswitch in this thread-post.\nI recently took a Intro-to-Python-course and stumbled upon {venv}. I was amazed to learn that in Python all previous versions stay available, so I could easily choose the version for a new virtual environment üí°"
  },
  {
    "objectID": "posts/2021-03-06-installing-multiple-r-versions-aside/index.html#note",
    "href": "posts/2021-03-06-installing-multiple-r-versions-aside/index.html#note",
    "title": "Installing & using multiple R versions aside",
    "section": "Note",
    "text": "Note\nI wrote this brief blogpost mainly for my future-self - having the steps outlined explicitly will hopefully save me time in the future. It took me repeated google-sessions in trying to understand the official R-docs and I was very grateful for the SO-answer - maybe another person might profit from this post as well - if so consider letting me know e.g.¬†by tweet.\n‚ö†Ô∏è A note of caution: I do not fully understand what is really happening with the commands above under the hood and I cannot be held responsible for whatever happens on your machine if you follow these steps.\nThey worked out on my computer(s) but for inquiries about what is really happening in the background consider following the official docs or ask on Stackoverflow!\nüíª Apple Mac OS X High Sierra."
  },
  {
    "objectID": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html",
    "href": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html",
    "title": "Getting PubMed metadata with RISmed directly into RStudio",
    "section": "",
    "text": "For my master‚Äôs thesis (stay tuned üòé) I came at a point where I was interested in having a closer look at publication meta data (e.g.¬†publications per year)\nPubMed usually does provide this service when you execute your search, for some reason it failed for my query\nBeing taught basic statistics I was determined to find a way to create the image myself‚Ä¶ and came across the amazing RISmed-üì¶\n\n‚û°Ô∏è This blog post highlights how I used the RISmed package and gives short code examples"
  },
  {
    "objectID": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html#introduction---what-were-the-problems-i-faced",
    "href": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html#introduction---what-were-the-problems-i-faced",
    "title": "Getting PubMed metadata with RISmed directly into RStudio",
    "section": "Introduction - what were the problems I faced?",
    "text": "Introduction - what were the problems I faced?\nThe topic of my master‚Äôs thesis - unfinished / missed / rationed nursing care - is an important topic in health services research with growing numbers of publications over the last years. Altough I did not have to use R extensively during my thesis, in one specific case I greatly profited from it:\nUsually, PubMed provides a small graphical display of the yearly publication count on each query as shown in the image below:\n\n\n\nPubMed year count\n\n\nFor some reason it failed for my exact search query. This was especially bad because I had to make a somehow valid statement that the publication numbers were increasing over the last years. If I only could get all meta data (i.e.¬†years) from my query (~900) into a spreadsheet‚Ä¶1\nAt some point I realized that the PubMed database should be accessible and I was sure that R has a solution to it - that‚Äôs how I found the RISmed-package."
  },
  {
    "objectID": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html#rismed-package",
    "href": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html#rismed-package",
    "title": "Getting PubMed metadata with RISmed directly into RStudio",
    "section": "RISmed package",
    "text": "RISmed package\nIn short: the RISmed package provides functions to extract bibliographic information from\nthe NCBI databases. In other words: you can extract the information from PubMed through R code - exactly what I needed!\n\nHow to use RISmed?\nFirst you need to install install.packages(\"RISmed\") or load the package:\n\n# load necessary packages\nlibrary(tidyverse)\nlibrary(RISmed)\n\nThen you specify the search_topic and search_query:\n\n# build the search topic\nsearch_topic <- 'missed care [TI] OR implicit rationing [TI] OR unfinished care [TI]'\n\n# the EUtilsSummary()-function gets information on your search results\n# (maximum results set as 1000, years between 1980 and 2019)\nsearch_query <- EUtilsSummary(search_topic, retmax=1000, mindate=1980,maxdate=2019)\n\nWarning in any(is.na(WhichArgs)) || sapply(WhichArgs, length) > 1: 'length(x) =\n3 > 1' in coercion to 'logical(1)'\n\n\nsummary() and QueryId get you quick overview of your results:\n\n# Printing the summary displays the actual results that are available\nsummary(search_query)\n\nQuery:\n(\"missed care\"[Title] OR \"implicit rationing\"[Title] OR \"unfinished care\"[Title]) AND 1980/01/01:2019/12/31[Date - Entry] \n\nResult count:  66\n\n# see the PMIIDs of our returned query\nQueryId(search_query)\n\n [1] \"31883182\" \"31850645\" \"31845542\" \"31773131\" \"31680364\" \"31596988\"\n [7] \"31583822\" \"31529752\" \"31334567\" \"31305955\" \"30937945\" \"30866129\"\n[13] \"30686577\" \"30681485\" \"30589706\" \"30475323\" \"30303195\" \"30303194\"\n[19] \"30303193\" \"30145041\" \"30095046\" \"29791753\" \"29655017\" \"29569380\"\n[25] \"29554590\" \"29471742\" \"29281908\" \"28978300\" \"28971888\" \"28960457\"\n[31] \"28844649\" \"28599196\" \"27556651\" \"27492884\" \"27322941\" \"27292861\"\n[37] \"27234155\" \"29718634\" \"26947419\" \"26259338\" \"26032730\" \"25794946\"\n[43] \"25563066\" \"25430513\" \"24681453\" \"24681452\" \"24481345\" \"24397252\"\n[49] \"24248553\" \"23991529\" \"23334645\" \"23084600\" \"22674763\" \"20661063\"\n[55] \"19590471\" \"18055900\" \"16323493\" \"11467274\" \"10862990\" \"9694173\" \n[61] \"10173241\" \"8611380\"  \"7549650\"  \"7549649\"  \"7795458\"  \"8332926\" \n\n\nIf you think your query gets you a reasonable number of results you can then further information on your records (i.e.¬†dowloading the information):\n\n# get the actual data from PubMed and store them in an object called records\nrecords <- EUtilsGet(search_query, type = \"efetch\", db = \"pubmed\")\n\n# check what kind of object \"records\" is\nclass(records)\n\n[1] \"Medline\"\nattr(,\"package\")\n[1] \"RISmed\"\n\n\nFor creating your final dataframe to analyse the data, you need to extract information as requested. You can choose either dataframe or list to store the results. Careful: If you extract Author() you need to choose list, otherwise the variable is dropped.\n\n# store it in either list or dataframe (Author() returns a list, therefore \n# list chosen here)\npubmed_data_list <- list('Title' = ArticleTitle(records), \n                         'Authors' = Author(records), \n                         'Year' = YearPubmed(records), \n                         'Journal' = Title(records),\n                         'PublicationType' = PublicationType(records),\n                         'Language' = Language(records))\n\n# version without Authors for dataframe\npubmed_data <- data.frame('Title' = ArticleTitle(records),\n                    'Year' = YearPubmed(records), \n                    'Journal' = Title(records),\n                    'Language' = Language(records))\n\nFinally, I could visually explore the year count:\n\n# plot the yearcount\nggplot(pubmed_data, aes(x = factor(Year))) +\n  geom_bar() +\n  scale_y_discrete() +\n  labs(x = \"Year\",\n       y = \"No. of publications\") +\n  theme_classic()"
  },
  {
    "objectID": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html#how-could-my-thesis-profit-from-the-rismed-package",
    "href": "posts/2019/2019-04-29-getting-pubmed-metadata-from-within-rstudio.html#how-could-my-thesis-profit-from-the-rismed-package",
    "title": "Getting PubMed metadata with RISmed directly into RStudio",
    "section": "How could my thesis profit from the RISmed package?",
    "text": "How could my thesis profit from the RISmed package?\nThe figure I created2 helped me visualize meta information on the publications: I could clearly see that the topic unfinished nursing care has been mentioned with increasing tendency in publications. This gave me valid data for accepting my assumption.\nDue to the nature of my thesis, I (sadly) didn‚Äôt have to use the exact numbers. Yet, I still learned two useful things üí°:\n\nUsing bibliographic information to inform your research may be helpful and should not be forgotten.\nI felt like I reached a whole new level of R‚Äôs numerous capabilities: Using an R package to connect to a web-database should not be the end of my discoveries üòÉ\n\nNotes on this post:\n\nBe careful with the search query - there can be differences in using different codes, see here: https://stackoverflow.com/questions/32994991/r-package-rismed-different-results-using-the-eutilsget-or-summary-function\nDowloading information from PubMed (EUtilsGet()) can take a while\nI had some trouble with long search terms (no further explanation found)\n\n\nOther resources I used\n\nhttps://datascienceplus.com/search-pubmed-with-rismed/\n\nhttps://www.r-bloggers.com/how-to-search-pubmed-with-rismed-package-in-r/\n\nhttps://www.rdocumentation.org/packages/RISmed/versions/2.1.4"
  },
  {
    "objectID": "posts/2019/2019-11-28-Using_purrr_map.html",
    "href": "posts/2019/2019-11-28-Using_purrr_map.html",
    "title": "Using purrr::map() to identify available datasets in a list",
    "section": "",
    "text": "What happened?\nRecently I wanted to explore plotting R for the first time and discovered the ggswissmaps-package.\nI‚Äôm new to the structure of geospatial data so I read the introductory vignette and followed the examples.\n\nExamples from the ggswissmaps-package\n\n#install.packages(\"ggswissmaps\")\n\nsuppressPackageStartupMessages(library(ggswissmaps))\nsuppressPackageStartupMessages(library(tidyverse))\n\n# Data frame with the coordinates of all swiss districts\nd <- shp_df[[\"g1b15\"]]\n\n# Look at the structure of the data frame\nglimpse(d)\n\nRows: 19,502\nColumns: 21\n$ long    <int> 679207, 680062, 679981, 680365, 680281, 680479, 680717, 681021‚Ä¶\n$ lat     <int> 245176, 244294, 244051, 243411, 241866, 241584, 240695, 240306‚Ä¶\n$ order   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,‚Ä¶\n$ hole    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,‚Ä¶\n$ piece   <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ group   <fct> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.‚Ä¶\n$ id      <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0‚Ä¶\n$ BZNR    <int> 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 10‚Ä¶\n$ KTNR    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ GRNR    <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,‚Ä¶\n$ AREA_HA <int> 11303, 11303, 11303, 11303, 11303, 11303, 11303, 11303, 11303,‚Ä¶\n$ X_MIN   <int> 671862, 671862, 671862, 671862, 671862, 671862, 671862, 671862‚Ä¶\n$ X_MAX   <int> 686462, 686462, 686462, 686462, 686462, 686462, 686462, 686462‚Ä¶\n$ Y_MIN   <int> 229137, 229137, 229137, 229137, 229137, 229137, 229137, 229137‚Ä¶\n$ Y_MAX   <int> 245396, 245396, 245396, 245396, 245396, 245396, 245396, 245396‚Ä¶\n$ X_CNTR  <int> 678300, 678300, 678300, 678300, 678300, 678300, 678300, 678300‚Ä¶\n$ Y_CNTR  <int> 235900, 235900, 235900, 235900, 235900, 235900, 235900, 235900‚Ä¶\n$ Z_MIN   <int> 380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 380, 38‚Ä¶\n$ Z_MAX   <int> 914, 914, 914, 914, 914, 914, 914, 914, 914, 914, 914, 914, 91‚Ä¶\n$ Z_AVG   <int> 561, 561, 561, 561, 561, 561, 561, 561, 561, 561, 561, 561, 56‚Ä¶\n$ Z_MED   <int> 557, 557, 557, 557, 557, 557, 557, 557, 557, 557, 557, 557, 55‚Ä¶\n\n# The cantons are identified by the KTNR column\n# Extract from this data the districts of two cantons (18 = Graub√ºnden, 21 = Ticino)\n\ntwo_cantons <- d %>% filter(KTNR  %in%  c(18, 21))\n\n# And draw the map\nmaps2_(two_cantons)\n\n\n\n\nThis worked quite fine - but I was more interested in plotting by language region, so I did the following:\n\n# add an aditional variable \"region\"\nd %>% \n  mutate(region = case_when(KTNR == 21 ~ \"Ticino\",\n                                 KTNR  %in% c(22, 23, 24, 25, 26) ~ \"Romandie\",\n                                 TRUE ~ \"Deutschschweiz\")) -> d\n\n# draw a ggplot \nggplot(d, aes(x = long, y = lat, group = group)) +\n  geom_polygon(aes(fill = factor(region)), color = \"black\") +\n  scale_fill_manual(name = \"Region\",\n                   values = c(\"Ticino\" = \"grey90\",\n                              \"Romandie\" = \"#b2df8a\",\n                              \"Deutschschweiz\" = \"#a6cee3\")) +\n  theme_void() +\n  theme(legend.position = \"bottom\") +\n  coord_equal()\n\n\n\n\n\n\nTroubleshooting\nWhat is the problem with this plot (aside from the ugly black color of the boundaries)? The boundaries correspond to district, not cantonal level (what I wanted). As the variable KTNR identifies the cantons, I did the following:\n\n# draw a ggplot and changed to aes(....group = KTNR)\nggplot(d, aes(x = long, y = lat, group = KTNR)) +\n  geom_polygon(aes(fill = factor(region)), color = \"black\") +\n  scale_fill_manual(name = \"Region\",\n                   values = c(\"Ticino\" = \"grey90\",\n                              \"Romandie\" = \"#b2df8a\",\n                              \"Deutschschweiz\" = \"#a6cee3\")) +\n  theme_void() +\n  theme(legend.position = \"bottom\") +\n  coord_equal()\n\n\n\n\n‚Ä¶It got even worse‚Ä¶\nI did not understand why at first. After a brief online exchange in the Rladies-Slack (sidenote: fantastic place to learn! üòé), I realized that my problem is with the data: aes(x = long, y = lat) in my dataframe correspond to district level not cantonal level. Unfortunately, the link on the website of the Federal Office of Statistics didn‚Äôt work either1, so what to do else?\nLook at the data structure:\n\n# a list containing 8 elements (dataframes)\n# which each contain lon/lat on different levels\nclass(shp_df)\n\n[1] \"list\"\n\n# very long output, not shown here\n#str(shp_df)\n\nI now knew that I could use the plot from above and check each element of the list - either by hand (corresponding to seven times copy/paste) or with purrr::map()!\n\n\nSolution\n\n# create a function to map over each element of the list to\n# identify if one is on cantonal-level\nmy_plot <- function(data){\n  \n  ggplot2::ggplot(data = data, ggplot2::aes(x = long, y = lat, group = group)) +\n    ggplot2::geom_polygon() +\n    ggplot2::theme_void() +\n    coord_equal()\n  \n}\n\nThen do the magic (1 simple line of code will give me 8 plots!):\n\n# map it over the list\npurrr::map(ggswissmaps::shp_df, ~my_plot(.x))\n\n$g1b15\n\n\n\n\n\n\n$g1g15_encl\n\n\n\n\n\n\n$g1g15_li\n\n\n\n\n\n\n$g1g15\n\n\n\n\n\n\n$g1k15\n\n\n\n\n\n\n$g1l15\n\n\n\n\n\n\n$g1r15\n\n\n\n\n\n\n$g1s15\n\n\n\n\n\nFrom the plots above I now know which dataframe to use:\n\n# solution: the second last element of the list is what I need\ncant_level <- \n  ggswissmaps::shp_df$g1k15 %>% \n      mutate(region = case_when(KTNR == 21 ~ \"Ticino\",\n                                KTNR  %in% c(22, 23, 24, 25, 26) ~ \"Romandie\",\n                                TRUE ~ \"Deutschschweiz\"))\n\n# draw the prettier graph\nggplot(cant_level, aes(x = long, y = lat, group = group)) +\n  geom_polygon(aes(fill = factor(region))) +\n  scale_fill_manual(name = \"Region\",\n                   values = c(\"Ticino\" = \"grey90\",\n                              \"Romandie\" = \"#b2df8a\",\n                              \"Deutschschweiz\" = \"#a6cee3\")) +\n  theme_void() +\n  theme(legend.position = \"bottom\") +\n  coord_equal()\n\n\n\n\nThe output is what I wanted - altough we could improve it, as the lakes (which are left out in the district-level data) are not shown here‚Ä¶\nEdit:\nthanks to the ggswissmaps-maintainer gibo‚Äôs help, the maps look now much prettier:\n\nggplot(cant_level, aes(x = long, y = lat, group = group)) +\n  geom_polygon(aes(fill = factor(region)), color = \"white\", size = 0.1) +\n  scale_fill_manual(name = \"Region\",\n                    values = c(\"Ticino\" = \"grey90\",\n                               \"Romandie\" = \"#b2df8a\",\n                               \"Deutschschweiz\" = \"#a6cee3\")) +\n  theme_void() +\n  theme(legend.position = \"bottom\") +\n  coord_equal() + # add a layer for the lakes\n  geom_polygon(aes(x = long, y = lat, group = group), \n               data = shp_df[[\"g1s15\"]], fill = NA, alpha = .5, color = \"#0529B3\", size = .1, lty = \"solid\")\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nIn the meantime, the package maintainer provided me with the working links: https://www.bfs.admin.ch/bfs/fr/home/services/geostat/geodonnees-statistique-federale.html.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2020/2020-03-16-using-pivot-longer-and-regex-for-data-wrangling.html",
    "href": "posts/2020/2020-03-16-using-pivot-longer-and-regex-for-data-wrangling.html",
    "title": "Using tidyr::pivot_longer() and regex for data wrangling",
    "section": "",
    "text": "TL;DR\nThis code shows you how you can effectively wrangle your dataframe from wide to long using tidyr::pivot_longer() combined with regular expressions for properly naming the variables.\n\n\nYour data is‚Ä¶ not in the right format!\nYou have a wide dataset of patient data, each patient identified through ID. They have been hospitalised multiple times, each place of hospitalisation and outcome listed in its own variable. Place and Outcome of a hospitalization are linked with the same suffix number, e.g.¬†_2_2:\n\n# load packages\nsuppressPackageStartupMessages(library(tidyverse))\n\n# create sample data\npatient_data <- \ntibble::tribble(~ID, ~Hosp_Place_1, ~Hosp_Outcome_1, ~Hosp_Place_2_2, \n                ~Hosp_Outcome_2_2, ~Hosp_Place_2_3, ~Hosp_Outcome_2_3, \n                1, \"London\", \"Alive\", \"Paris\", \"alive\", \"Rome\", \"dead\",\n                2, \"Paris\", \"alive\", \"Rome\", \"alive\", \"London\", \"alive\",\n                3, \"Berne\", \"dead\", NA_character_, NA_character_, NA_character_, NA_character_) \n\n# look at data\npatient_data\n\n# A tibble: 3 √ó 7\n     ID Hosp_Place_1 Hosp_Outcome_1 Hosp_Place_2_2 Hosp_Outcome_2_2\n  <dbl> <chr>        <chr>          <chr>          <chr>           \n1     1 London       Alive          Paris          alive           \n2     2 Paris        alive          Rome           alive           \n3     3 Berne        dead           <NA>           <NA>            \n# ‚Ä¶ with 2 more variables: Hosp_Place_2_3 <chr>, Hosp_Outcome_2_3 <chr>\n\n\nPatient No.¬†3 died in his first hospitatisation, so the following variables are listed NA.\nFor some analysis, this data structure would work ok, but for your specific questions you need to switch the unit of analysis to ‚Äúhospitalisation‚Äù instead of ‚Äúpatient‚Äù. In other words, you‚Äôd like to switch the data from wide to long.\nThanks to the tidyverse‚Äôs initiative of making clear function names, it might be obvious, that tidyr::pivot_longer() should do what you want.\n\n\nFamiliarize yourself with the function - What to do with tidyr::pivot_longer()?\nThe first step is to initially think about, what the outcome should look like and what input-arguments the function takes, so let‚Äôs do this:\n\n# tidyr::pivot_long() and its arguments\ntidyr::pivot_longer(data, \n                    cols, \n                    names_to = \"name\", \n                    names_prefix = NULL, \n                    names_sep = NULL, \n                    names_pattern = NULL,\n                    names_ptypes = list(),\n                    names_repair = \"check_unique\",\n                    values_to = \"value\",\n                    values_drop_na = FALSE,\n                    values_ptypes = list())\n\nAs you can see, only data and cols are effectively needed, so let‚Äôs try that. As I want to exclude the Patient-ID from pivoting, I remove this line from pivoting:\n\n# as with all the tidyverse functions you can easily pipe-in the data as \n# the first argument\n\n# '-ID' means, that all variables are used other than ID\npatient_data %>% \n  pivot_longer(cols = -ID)\n\n# A tibble: 18 √ó 3\n      ID name             value \n   <dbl> <chr>            <chr> \n 1     1 Hosp_Place_1     London\n 2     1 Hosp_Outcome_1   Alive \n 3     1 Hosp_Place_2_2   Paris \n 4     1 Hosp_Outcome_2_2 alive \n 5     1 Hosp_Place_2_3   Rome  \n 6     1 Hosp_Outcome_2_3 dead  \n 7     2 Hosp_Place_1     Paris \n 8     2 Hosp_Outcome_1   alive \n 9     2 Hosp_Place_2_2   Rome  \n10     2 Hosp_Outcome_2_2 alive \n11     2 Hosp_Place_2_3   London\n12     2 Hosp_Outcome_2_3 alive \n13     3 Hosp_Place_1     Berne \n14     3 Hosp_Outcome_1   dead  \n15     3 Hosp_Place_2_2   <NA>  \n16     3 Hosp_Outcome_2_2 <NA>  \n17     3 Hosp_Place_2_3   <NA>  \n18     3 Hosp_Outcome_2_3 <NA>  \n\n# I could have put the following instead, meaning selecting the variables I want\n# but it was generally shorter to drop just the ID\n# patient_data %>%\n#   pivot_longer(cols = Hosp_Place_1:Hosp_Outcome_2_3)\n\nSomething clearly happened, but name and value are not exactly what we want here.\nThe colnames ‚Äúname‚Äù and ‚Äúvalue‚Äù are actually coming from the default arguments.\nWhat is now the next step?\n\n\nMental image of desired outcome - How should my dataframe look like?\nMy desired output is a dataframe with the colum names ID, Hosp_Place and Hosp_Outcome. Additionally, I want a variable - lets call it hosp_sequence - that captures the number of the hospitalisation (you remember the suffix of the original variable names).\ntidyr::pivot_longer()‚Äôs names_to =-arguments states in the help-page:\nCan be a character vector, creating multiple columns, if names_sep or names_pattern is provided.\nIf you can detect any patterns in the column names, its possible to use them for the column naming. If we look at Hosp_Place_1 and Hosp_Outcome_1 we can clearly see a pattern: The information I want as name is Hosp_Place and Hosp_Outcome and the number followed should be put in variable called hosp_sequence.\nThis translates to something like (Hosp_Place)_(1) where the parts in brackets correspond to the inputs given in names_to =. With the .value-argument, I can easily take over the string as it is.\nI actually found this very confusing (honestly - still do‚Ä¶) and I had great help for defining the regular expression from R4DS1.\nFinally, this is the code we need:\n\n# this code should do the trick\npatient_data %>% \n  pivot_longer(cols = -ID, \n               names_to = c(\".value\", \"hosp_sequence\"),\n               names_pattern = '(^[A-z]+_[A-z]+)_([0-9].*)')\n\n# A tibble: 9 √ó 4\n     ID hosp_sequence Hosp_Place Hosp_Outcome\n  <dbl> <chr>         <chr>      <chr>       \n1     1 1             London     Alive       \n2     1 2_2           Paris      alive       \n3     1 2_3           Rome       dead        \n4     2 1             Paris      alive       \n5     2 2_2           Rome       alive       \n6     2 2_3           London     alive       \n7     3 1             Berne      dead        \n8     3 2_2           <NA>       <NA>        \n9     3 2_3           <NA>       <NA>        \n\n\nWait, what is happening with rows 8 and 9? This is my deceased Patient No.¬†3 an those are not hospitalisations anymore - how do I drop those rows?\n\n# you can either use dplyr::drop_na() or specify the built-in argument to TRUE\npatient_data %>% \n  pivot_longer(cols = -ID, \n               names_to = c(\".value\", \"hosp_sequence\"),\n               names_pattern = '(^[A-z]+_[A-z]+)_([0-9].*)', \n               values_drop_na = TRUE)\n\n# A tibble: 7 √ó 4\n     ID hosp_sequence Hosp_Place Hosp_Outcome\n  <dbl> <chr>         <chr>      <chr>       \n1     1 1             London     Alive       \n2     1 2_2           Paris      alive       \n3     1 2_3           Rome       dead        \n4     2 1             Paris      alive       \n5     2 2_2           Rome       alive       \n6     2 2_3           London     alive       \n7     3 1             Berne      dead        \n\n\n\n\nComment\nI wrote this blogpost after after solving exactly this issue with a real dataset for a colleague.\nMy work as a research programmer allows me to dive into data wrangling problems on a regular basis. As I learned most of my R skills from other blogposts from the fantastic R community, I started to write up some of the problems I encountered for others. I also use my previous blogposts sometimes, when I have to dig up old code‚Ä¶\nAny comments from your side? Let me know!\n\n\n\n\n\nFootnotes\n\n\nhttps://rfordatascience.slack.com/archives/C8K09CDNZ/p1584129595187200 If you are not already on this slack - sign up for it! Its just so great, low key help and great learning opportunities to just dive through the topics. ‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cath Blatter",
    "section": "",
    "text": "Hi!\nI‚Äôm a registered-nurse-turned-data-lover and PhD student at a Swiss university. I like to build and hack code to make research processes faster, less ambiguous and more reproducible and aim to provide meaningful data insights and outputs for use in clinical settings.\n\n\n\nEducation\n\nsince 2020: PhD student\nUniversity of Basel\n2019: MSc Nursing\nUniversity of Basel\n2012: Registered Nurse (RN)\n\n\n\n\nWork experience\n\nsince 2020: Teaching assistant\nsince 2016: Research assistant\nUniversity of Basel\n2012-2016: RN in several Swiss acute care hospitals\n\n\n\n\n\n\nExperience\nI have broad experience in data preparation and analysis in health services research (i.e., survey studies and routinely collected data from electronic health records). My latest work includes development and implementation of analytic workflows for teams with a non-technical background, including but not limited to:\n\nmultilingual reporting of study results (descriptive & bench marked)\n\ndevelopment of several internally-used R packages\n\ndata visualization for communication with research and practice stakeholders\n\nInstruction, guidance and consultancy on programming / data management"
  },
  {
    "objectID": "listings.html",
    "href": "listings.html",
    "title": "Cath Blatter",
    "section": "",
    "text": "Different approaches to rename variables\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2022\n\n\nCath Blatter\n\n\n\n\n\n\n  \n\n\n\n\nAn (ever growing) list of random things in R\n\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2022\n\n\nCath Blatter\n\n\n\n\n\n\n  \n\n\n\n\nInstalling & using multiple R versions aside\n\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2021\n\n\nCath Blatter\n\n\n\n\n\n\n  \n\n\n\n\nUsing tidyr::pivot_longer() and regex for data wrangling\n\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2020\n\n\nCath Blatter\n\n\n\n\n\n\n  \n\n\n\n\nUsing purrr::map() to identify available datasets in a list\n\n\n\n\n\n\n\npurrr\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2019\n\n\nCath Blatter\n\n\n\n\n\n\n  \n\n\n\n\nGetting PubMed metadata with RISmed directly into RStudio\n\n\n\n\n\n\n\nRISmed\n\n\n\n\n\n\n\n\n\n\n\nApr 29, 2019\n\n\nCatherine Blatter\n\n\n\n\n\n\nNo matching items"
  }
]